# Modul 5: Ansvar, risk och professionellt omd√∂me
## Etik, bias, transparens, informationss√§kerhet och regelverk

**Tid:** 60 minuter  
**Typ:** F√∂rdjupning  
**Status:** Ej p√•b√∂rjad

---

## L√§randem√•l

Efter denna modul ska deltagaren kunna:

1. **Identifiera** centrala riskomr√•den vid AI-anv√§ndning i konsultarbete
2. **F√∂rklara** vad bias inneb√§r och hur det kan p√•verka AI-resultat
3. **Bed√∂ma** vilken information som √§r l√§mplig att dela med AI-verktyg
4. **Beskriva** huvuddragen i EU:s AI-f√∂rordning och svensk till√§mpning
5. **F√∂rst√•** hur OSL, GDPR och arbetsr√§ttsliga regler p√•verkar AI-anv√§ndning
6. **G√∂ra** professionella avv√§gningar kring AI-anv√§ndning i specifika situationer

---

## Nyckelbegrepp

### Bias (snedvridning)
Systematiska fel i AI-resultat som beror p√• snedvridning i tr√§ningsdata eller modelldesign. Kan leda till or√§ttvisa eller missvisande utfall.

### Transparens
√ñppenhet om hur AI anv√§nds, vilka begr√§nsningar som finns, och n√§r AI har bidragit till ett resultat.

### Hallucination
N√§r AI genererar information som verkar trov√§rdig men √§r helt fabricerad ‚Äì p√•hittade fakta, k√§llor eller citat.

### AI-literacy
Grundl√§ggande f√∂rst√•else f√∂r hur AI fungerar, dess m√∂jligheter och begr√§nsningar ‚Äì en f√∂ruts√§ttning f√∂r ansvarsfull anv√§ndning.

### EU AI Act
EU:s f√∂rordning om artificiell intelligens ‚Äì v√§rldens f√∂rsta omfattande AI-lagstiftning med krav baserade p√• riskniv√•.

---

## Huvudinneh√•ll

### 1. Centrala riskomr√•den

#### A. Kvalitetsrisker

| Risk | Beskrivning | Konsekvenspotential |
|------|-------------|---------------------|
| **Hallucinationer** | AI fabricerar fakta, siffror, k√§llor | Felaktiga beslutsunderlag |
| **Inkonsekvens** | Samma fr√•ga ger olika svar | Op√•litlighet |
| **F√∂r√•ldrad information** | AI:s kunskap har cutoff-datum | Missade f√∂r√§ndringar |
| **Kontextblindhet** | AI f√∂rst√•r inte kundens specifika situation | Irrelevanta f√∂rslag |

**Hur minskar vi kvalitetsrisk?**
- Verifiera alltid fakta och siffror
- Ange tydlig kontext i promptar
- Behandla AI-output som utkast, inte f√§rdig produkt
- Var extra skeptisk till specifika p√•st√•enden

#### B. Etiska risker

| Risk | Beskrivning | Konsekvenspotential |
|------|-------------|---------------------|
| **Bias** | Systematisk snedvridning mot grupper | Diskriminering, or√§ttvisa |
| **Brist p√• representation** | Tr√§ningsdata speglar inte alla perspektiv | Blinda fl√§ckar |
| **Automatiserad or√§ttvisa** | Beslut baserade p√• biased AI | F√∂rst√§rkt or√§ttvisa |

**Hur minskar vi etisk risk?**
- Var medveten om att bias existerar
- Ifr√•gas√§tt resultat som verkar ensidiga
- Komplettera med m√§nsklig bed√∂mning
- Var extra f√∂rsiktig vid beslut som p√•verkar m√§nniskor

#### C. Informationss√§kerhetsrisker

| Risk | Beskrivning | Konsekvenspotential |
|------|-------------|---------------------|
| **Datal√§ckage** | K√§nslig information n√•r AI-leverant√∂r | Sekretessbrott |
| **Tr√§ningsdata** | Information kan anv√§ndas f√∂r tr√§ning | F√∂rlust av konfidentialitet |
| **Tredjepartsdeling** | Data kan delas vidare | Avtalsbott |

**Hur minskar vi informationss√§kerhetsrisk?**
- Anonymisera k√§nslig information
- Anv√§nd godk√§nda verktyg enligt policy
- Anta att allt du skriver kan lagras
- Dela aldrig personuppgifter, aff√§rshemligheter eller sekretessbelagd information

### 2. Bias ‚Äì vad det √§r och varf√∂r det spelar roll

#### Hur bias uppst√•r

```
TR√ÑNINGSDATA ‚Üí MODELL ‚Üí OUTPUT
   (biased)   (l√§r sig)  (biased)
```

1. **Tr√§ningsdata** speglar historiska m√∂nster, inklusive f√∂rdomar
2. **Modellen** l√§r sig att √•terskapa dessa m√∂nster
3. **Output** f√∂rst√§rker eller reproducerar snedvridningen

#### Typer av bias att vara medveten om:

| Typ | Beskrivning | Exempel |
|-----|-------------|---------|
| **Historisk bias** | Data speglar historiska or√§ttvisor | Rekryteringsmodeller som missgynnar kvinnor |
| **Representationsbias** | Vissa grupper underrepresenterade | Ansiktsigenk√§nning som fungerar s√§mre f√∂r m√∂rkhyade |
| **Spr√•kbias** | Engelska dominerar, andra spr√•k underrepresenterade | S√§mre kvalitet p√• svenska svar |
| **Kulturell bias** | V√§sterl√§ndska perspektiv dominerar | Antaganden som inte g√§ller globalt |
| **Bekr√§ftelsebias** | AI bekr√§ftar fr√•gest√§llarens antaganden | "Ja-s√§gande" utan kritisk granskning |

#### Fr√•gor att st√§lla sig:

- Vems perspektiv saknas i detta svar?
- G√§ller detta i v√•r specifika kontext?
- Har jag fr√•gat p√• ett ledande s√§tt?
- Finns det alternativa tolkningar?

### 3. Informationss√§kerhet i praktiken

#### Vad du ALDRIG ska dela med √∂ppna AI-verktyg:

üö´ **Personuppgifter** ‚Äì namn, personnummer, kontaktuppgifter

üö´ **K√§nsliga personuppgifter** ‚Äì h√§lsa, religion, politisk √•sikt

üö´ **Aff√§rshemligheter** ‚Äì strategier, opublicerade planer

üö´ **Sekretessbelagd information** ‚Äì enligt avtal eller lag

üö´ **Autentiseringsuppgifter** ‚Äì l√∂senord, API-nycklar

üö´ **Kundspecifik information** ‚Äì utan medgivande

#### S√§krare alternativ:

| Ist√§llet f√∂r | G√∂r s√• h√§r |
|--------------|------------|
| "Analysera avtalet med F√∂retag X" | Anonymisera: "Analysera ett IT-avtal med en kommunal kund" |
| "Sammanfatta intervju med Anna Andersson" | Ta bort namn: "Sammanfatta intervju med en mellanchef" |
| "V√•r budget √§r 5 MSEK" | Generalisera: "Budget i storleksordningen 3-7 MSEK" |
| "V√•r strategi f√∂r 2025 √§r..." | Dela inte alls ‚Äì f√∂r k√§nsligt |

#### Verktygsval och policy:

- **F√∂lj alltid** Curagos och kundens policy f√∂r AI-verktyg
- **Fr√•ga** om du √§r os√§ker p√• vad som √§r till√•tet
- **Dokumentera** inte vilka AI-verktyg du anv√§nt om det inte √§r explicit efterfr√•gat
- **Var medveten** om att olika verktyg har olika datapolicy

### 4. Regelverk ‚Äì EU och Sverige

#### A. DIGG/IMY:s 18 riktlinjer f√∂r generativ AI (januari 2025)

Den 21 januari 2025 lanserade DIGG och IMY nationella riktlinjer f√∂r generativ AI i offentlig f√∂rvaltning. Detta √§r den mest aktuella svenska v√§gledningen och t√§cker sju huvudomr√•den:

| Omr√•de | Fokus |
|--------|-------|
| **Ledning och ansvar** | Styrning, roller, ansvarsf√∂rdelning |
| **Informationss√§kerhet** | Klassificering, riskhantering, tekniska krav |
| **Upphovsr√§tt** | Anv√§ndning av upphovsr√§ttsskyddat material |
| **Dataskydd (GDPR)** | Personuppgiftshantering, konsekvensbed√∂mning |
| **Etik** | Ansvarsfull anv√§ndning, m√§nsklig kontroll |
| **Arbetsr√§tt** | MBL, facklig samverkan, personalfr√•gor |
| **Anskaffning** | Upphandling, leverant√∂rskrav |

**Viktiga principer fr√•n riktlinjerna:**

1. **"Human in the loop"** ‚Äì M√§nsklig kontroll i beslutsfattande
2. **Transparens** ‚Äì √ñppenhet om AI-anv√§ndning
3. **H√•llbarhet** ‚Äì Milj√∂- och resursh√§nsyn
4. **Integritetsskydd** ‚Äì GDPR-efterlevnad fr√•n start

**Praktisk anv√§ndning:**
- Riktlinjerna finns p√• **digg.se/ai**
- Uppdateras l√∂pande i takt med utvecklingen
- Riktar sig till alla i offentlig f√∂rvaltning ‚Äì fr√•n medarbetare till ledning

> **F√∂r konsulter:** Riktlinjerna √§r ett utm√§rkt referensdokument att h√§nvisa till i kunddialoger. De ger legitimitet och trygghet f√∂r kunder som √§r os√§kra p√• AI-anv√§ndning.

---

#### B. EU AI Act ‚Äì √ñversikt

EU:s AI-f√∂rordning (AI Act) tr√§dde i kraft i augusti 2024 och √§r v√§rldens f√∂rsta omfattande AI-lagstiftning. Den p√•verkar hur AI f√•r utvecklas och anv√§ndas inom EU.

**Riskbaserat ramverk:**

| Riskniv√• | Exempel | Krav |
|----------|---------|------|
| **Oacceptabel risk** | Social po√§ngs√§ttning, manipulation | F√∂rbjudet |
| **H√∂g risk** | AI i rekrytering, kreditbed√∂mning, utbildning | Strikt reglerat |
| **Begr√§nsad risk** | Chatbotar, AI-genererat inneh√•ll | Transparenskrav |
| **Minimal risk** | Spamfilter, rekommendationssystem | Inga specifika krav |

**Viktiga datum:**

| Datum | Vad h√§nder |
|-------|------------|
| Februari 2025 | F√∂rbjudna AI-praktiker f√∂rbjuds, AI-literacy-krav b√∂rjar g√§lla |
| Augusti 2025 | Regler f√∂r generativ AI (GPAI-modeller) g√§ller |
| Augusti 2026 | Huvuddelen av regelverket g√§ller fullt ut |
| Augusti 2027 | Regler f√∂r h√∂grisk-AI i produkter g√§ller |

**Sverige:** Regeringen har gett IMY (Integritetsskyddsmyndigheten) och DIGG samordningsansvar f√∂r AI-tillsyn. AI Sweden st√∂djer implementering i n√§ringsliv och offentlig sektor.

---

#### B. GDPR och AI ‚Äì Svensk till√§mpning

GDPR (Dataskyddsf√∂rordningen) g√§ller fullt ut f√∂r AI som behandlar personuppgifter. IMY har utf√§rdat v√§gledning specifikt f√∂r AI.

**Centrala principer:**

| Princip | Betydelse f√∂r AI |
|---------|------------------|
| **√Ñndam√•lsbegr√§nsning** | Data insamlad f√∂r ett syfte f√•r inte utan vidare anv√§ndas f√∂r AI-tr√§ning |
| **Uppgiftsminimering** | Samla bara in data som verkligen beh√∂vs |
| **Riktighet** | AI-output om personer m√•ste vara korrekt |
| **Lagringsminimering** | Radera data n√§r den inte l√§ngre beh√∂vs |
| **R√§ttslig grund** | M√•ste finnas laglig grund f√∂r behandlingen |

**S√§rskilt viktigt:**
- **Automatiserat beslutsfattande (Art. 22):** Beslut som enbart baseras p√• automatiserad behandling och har r√§ttslig verkan kr√§ver m√§nsklig granskning
- **Konsekvensbed√∂mning:** Kr√§vs ofta vid AI-anv√§ndning som behandlar personuppgifter
- **Registerf√∂ring:** Organisationen m√•ste dokumentera vilka AI-verktyg som anv√§nds

**IMY:s v√§gledning:** IMY har publicerat specifik v√§gledning om AI och personuppgifter. Kolla imy.se f√∂r aktuella riktlinjer.

---

#### C. OSL ‚Äì Offentlighets- och sekretesslagen

F√∂r konsulter som arbetar mot offentlig sektor √§r OSL central.

**Huvudprinciper:**

| Fr√•ga | Betydelse |
|-------|-----------|
| **Allm√§nna handlingar** | AI-genererade dokument kan bli allm√§nna handlingar |
| **Sekretess** | Sekretessbelagd information f√•r INTE delas med AI-verktyg utanf√∂r myndigheten |
| **Molntj√§nster** | Anv√§ndning av amerikanska AI-tj√§nster √§r problematisk f√∂r sekretessbelagd info |
| **Utl√§mnande** | Om AI-output sparas kan det beg√§ras ut |

**Praktisk konsekvens f√∂r konsulter:**

üö´ Dela aldrig sekretessbelagd information med √∂ppna AI-verktyg som ChatGPT eller Claude

‚ö†Ô∏è Var medveten om att kommuner/regioner kan ha striktare regler

‚úÖ Anv√§nd anonymisering eller godk√§nda verktyg enligt kundens policy

**Schrems II-problematiken:** √ñverf√∂ring av personuppgifter till USA (d√§r de flesta AI-leverant√∂rer finns) √§r juridiskt komplicerat. M√•nga offentliga organisationer har d√§rf√∂r restriktioner f√∂r amerikanska molntj√§nster.

---

#### D. Arbetsr√§tt och facklig samverkan (MBL)

Vid AI-inf√∂rande i organisationer g√§ller MBL (Medbest√§mmandelagen).

**N√§r g√§ller MBL?**
- Inf√∂rande av nya AI-verktyg som p√•verkar arbetssituationen
- F√∂r√§ndringar i arbetsuppgifter till f√∂ljd av AI
- AI-baserad √∂vervakning eller prestationsm√§tning

**Arbetsgivarens skyldigheter:**
1. **Informationsplikt** ‚Äì Informera facket om planerade f√∂r√§ndringar
2. **F√∂rhandlingsskyldighet** ‚Äì F√∂rhandla innan beslut fattas
3. **R√§tt till insyn** ‚Äì Fackliga representanter har r√§tt att f√∂rst√• hur AI anv√§nds

**F√∂r konsulter:** Om uppdraget handlar om AI-inf√∂rande, s√§kerst√§ll att kunden hanterar den fackliga processen korrekt. Det √§r ofta en framg√•ngsfaktor ‚Äì inte bara ett juridiskt krav.

---

#### E. Upphandling och AI (LOU/LUF)

F√∂r offentliga kunder som upphandlar AI-tj√§nster g√§ller LOU (Lagen om offentlig upphandling).

**Relevanta aspekter:**

| Aspekt | √ñverv√§gande |
|--------|-------------|
| **Kravspecifikation** | Definiera funktionskrav, inte specifika produkter |
| **Dataskydd** | St√§ll krav p√• GDPR-compliance |
| **Lokalisering** | √ñverv√§g krav p√• datalagring inom EU |
| **Transparens** | Kan kr√§va insyn i hur AI-modellen fungerar |
| **Etik** | M√∂jligt att st√§lla etiska krav i upphandlingen |

**DIGG:s v√§gledning:** DIGG har publicerat st√∂d f√∂r upphandling av AI i offentlig sektor.

---

#### F. Vad betyder regelverken f√∂r konsulter?

| Omr√•de | Din skyldighet |
|--------|----------------|
| **AI-literacy** | Du f√∂rv√§ntas ha grundl√§ggande f√∂rst√•else (EU AI Act) |
| **Transparens** | Ber√§tta n√§r AI anv√§nts i vissa situationer |
| **Dataskydd** | F√∂lj GDPR, anonymisera personuppgifter |
| **Sekretess** | Respektera OSL i offentliga uppdrag |
| **Kundr√•dgivning** | Hj√§lpa kunder f√∂rst√• sina skyldigheter |
| **Facklig process** | P√•minn kunder om MBL vid AI-inf√∂rande |

### 5. Professionellt omd√∂me ‚Äì ett ramverk

#### Bed√∂mningsfr√•gor f√∂re AI-anv√§ndning

| Fr√•ga | Om JA ‚Üí |
|-------|---------|
| Inneh√•ller uppgiften k√§nslig information? | Anonymisera eller avst√• |
| √Ñr faktagranskning kritisk? | Planera f√∂r verifiering |
| Kan fel f√• allvarliga konsekvenser? | Var extra noggrann med granskning |
| Ber√∂r det beslut om m√§nniskor? | Var medveten om bias |
| F√∂rv√§ntar sig kunden att AI inte anv√§nds? | Var transparent eller avst√• |

#### Beslutstrappa f√∂r os√§kra situationer

```
1. Kan jag verifiera resultatet?
   ‚Üì NEJ ‚Üí Anv√§nd inte AI f√∂r denna uppgift
   ‚Üì JA
2. √Ñr informationen l√§mplig att dela?
   ‚Üì NEJ ‚Üí Anonymisera eller abstrahera
   ‚Üì JA
3. F√∂rst√•r jag output tillr√§ckligt f√∂r att ta ansvar?
   ‚Üì NEJ ‚Üí F√∂rdjupa dig eller fr√•ga kollega
   ‚Üì JA
4. Anv√§nd AI, granska noggrant, ta √§garskap
```

#### Situationer som kr√§ver extra omd√∂me

| Situation | √ñverv√§gande |
|-----------|-------------|
| Analys som p√•verkar anst√§llningar | H√∂g risk f√∂r bias, m√§nsklig granskning kritisk |
| Juridiska dokument | AI f√∂rst√•r inte juridisk kontext |
| Medicinsk eller h√§lsorelaterad r√•dgivning | Kan vara livsavg√∂rande, undvik AI |
| Politiskt k√§nsliga fr√•gor | AI kan ha bias, var extra kritisk |
| Beslut om barn eller utsatta grupper | Extra h√∂ga krav p√• noggrannhet |

---

## Praktiska exempel

### Exempel 1: Dilemma om informationsdelning

**Situation:** Du ska sammanfatta en rapport som inneh√•ller kommunens planerade besparingsprogram med namngivna f√∂rvaltningar och budgetsiffror.

**Alternativ:**
1. Klistra in hela rapporten i ChatGPT
2. Anonymisera och generalisera innan AI-anv√§ndning
3. Sammanfatta manuellt

**R√§tt val:** Alternativ 2 eller 3, beroende p√• k√§nslighet. Aldrig alternativ 1 med verkliga namn och siffror.

### Exempel 2: Bias i rekryteringsanalys

**Situation:** AI hj√§lper dig analysera CV:n f√∂r en rekryteringsprocess.

**Risk:** AI kan systematiskt nedv√§rdera kandidater baserat p√• namn, utbildningsbakgrund eller andra faktorer som korrelerar med k√∂n eller etnicitet.

**√Ötg√§rd:** 
- Anonymisera CV:n f√∂re analys
- L√•t AI bara extrahera information, inte ranka
- M√§nsklig bed√∂mning av slutkandidater

### Exempel 3: Transparens om AI-anv√§ndning

**Situation:** Du har anv√§nt AI f√∂r att skriva f√∂rsta utkast till en rapport. Kunden fr√•gar hur rapporten tagits fram.

**B√§ttre svar:** "Jag har anv√§nt AI som st√∂d f√∂r struktur och formulering, men all analys, slutsatser och fakta √§r granskade och validerade av mig. Rapporten representerar min professionella bed√∂mning."

**S√§mre svar:** "Jag skrev den." (om det inte st√§mmer)

---

## Praktiska √∂vningar

### √ñvning 1: Riskbed√∂mning (15 min)

**Scenario:** Du ska anv√§nda AI f√∂r f√∂ljande uppgifter. Bed√∂m riskniv√• (L√•g/Medel/H√∂g) och motivera:

1. Sammanfatta publikt tillg√§ngliga √•rsredovisningar
2. Analysera intervjuer med kommunanst√§llda om arbetsmilj√∂
3. Skriva utkast till e-post till kund
4. Ta fram beslutsunderlag om personalf√∂r√§ndringar
5. Generera f√∂rslag p√• workshop√∂vningar

**Diskutera:** Hur p√•verkar riskniv√•n hur du anv√§nder AI?

### √ñvning 2: Anonymiserings√∂vning (10 min)

**Uppgift:** Skriv om f√∂ljande text s√• den kan anv√§ndas med √∂ppna AI-verktyg:

*"Jag intervjuade Anna Svensson, ekonomichef p√• Stenungsunds kommun, om deras nya budgetprocess. Hon ber√§ttade att de har 450 MSEK i budget och planerar neddragningar p√• socialf√∂rvaltningen med 15 anst√§llda."*

<details>
<summary>Visa f√∂rslag</summary>

*"Jag intervjuade ekonomichefen p√• en mellanstor kommun om deras nya budgetprocess. Hon ber√§ttade att de har en budget i intervallet 300-500 MSEK och planerar personalf√∂r√§ndringar p√• en av f√∂rvaltningarna."*

</details>

### √ñvning 3: Dilemmasituation (15 min)

**Scenario:** En kund ber dig analysera medarbetarenk√§ter f√∂r att identifiera "problemindivider" med hj√§lp av AI.

**Diskutera i grupp:**
1. Vilka etiska problem ser ni?
2. Hur skulle ni svara kunden?
3. Finns det ett s√§tt att hj√§lpa kunden som √§r etiskt f√∂rsvarbart?
4. Var g√•r gr√§nsen f√∂r vad vi som konsulter ska g√∂ra?

### √ñvning 4: DIGG/IMY:s riktlinjer i praktiken (15 min)

**Uppgift:** G√• till digg.se/ai och bekanta dig med de 18 riktlinjerna.

**Scenario:** Din kund (en mellanstor kommun) vill b√∂rja anv√§nda generativ AI f√∂r att:
- Sammanfatta medborgarf√∂rslag
- Skriva utkast till beslutsunderlag
- Besvara vanliga fr√•gor via chattbot p√• hemsidan

**Uppgift i par:**
1. Identifiera vilka av de 7 omr√•dena i riktlinjerna som √§r mest relevanta
2. Lista 3-5 konkreta fr√•gor kunden b√∂r besvara innan de b√∂rjar
3. F√∂resl√• en "quick win" ‚Äì n√•got kunden kan b√∂rja med som har l√•g risk

**Diskutera:** Hur kan ni som konsulter anv√§nda riktlinjerna i kunddialoger?

### √ñvning 5: Sj√§lvreflektion (Hemuppgift)

T√§nk p√• ett uppdrag du nyligen arbetat med:
1. Hade AI kunnat bidra? Hur?
2. Vilka risker hade det inneburit?
3. Hur hade du hanterat dessa risker?
4. Hade du beh√∂vt vara transparent mot kunden om AI-anv√§ndning?

---

## Reflektionsfr√•gor

1. Har du sj√§lv upplevt att AI gett dig bias-pr√§glad information? Hur m√§rkte du det?

2. Var g√•r din personliga gr√§ns f√∂r vilken information du delar med AI-verktyg?

3. Hur skulle du reagera om en kollega anv√§nde AI f√∂r n√•got du bed√∂mer ol√§mpligt?

4. Tror du att kunder f√∂rv√§ntar sig att konsulter anv√§nder AI? Borde de informeras?

5. Hur balanserar du effektivitet mot s√§kerhet och etik?

---

## F√∂rdjupning & externa resurser

### Prim√§ra svenska resurser (2025)
| Resurs | URL | Beskrivning |
|--------|-----|-------------|
| **[DIGG: AI f√∂r offentlig f√∂rvaltning](https://www.digg.se/ai-for-offentlig-forvaltning)** | digg.se/ai | De 18 riktlinjerna + v√§gledning, webbinarier |
| **[IMY: AI och dataskydd](https://www.imy.se/)** | imy.se | GDPR-v√§gledning specifikt f√∂r AI |
| **[AI-kommissionens f√§rdplan](https://www.regeringen.se/rattsliga-dokument/statens-offentliga-utredningar/2024/11/sou-202489/)** | regeringen.se | Nationell strategi och handlingsplan |
| **[AI Sweden](https://www.ai.se/sv)** | ai.se | Nationellt centrum ‚Äì resurser, n√§tverk, utbildning |
| **[SKR: AI i kommuner](https://skr.se/digitaliseringivalfarden/datadrivenutveckling/artificiellintelligensai.716.html)** | skr.se | Erfarenheter och st√∂d f√∂r kommunsektorn |

### Svenska myndigheter med AI-ansvar
| Myndighet | Roll |
|-----------|------|
| **[DIGG](https://www.digg.se)** | Samordning, v√§gledning, AI-verkstad |
| **[IMY](https://www.imy.se)** | Dataskyddstillsyn, regulatorisk sandl√•da |
| **[Upphandlingsmyndigheten](https://www.upphandlingsmyndigheten.se)** | V√§gledning om upphandling av AI |
| **[Finansinspektionen](https://www.fi.se)** | AI i finanssektorn |
| **[Socialstyrelsen](https://www.socialstyrelsen.se)** | AI i v√•rd och omsorg |
| **[Skolverket](https://www.skolverket.se)** | AI i utbildning |

### EU-resurser
| Resurs | Beskrivning |
|--------|-------------|
| **[AI Act Explorer](https://artificialintelligenceact.eu/)** | Komplett guide till EU AI Act |
| **[EU AI Office](https://digital-strategy.ec.europa.eu/en/policies/ai-office)** | Officiell EU-resurs f√∂r AI-reglering |
| **[EDPB](https://www.edpb.europa.eu/)** | Europeiska dataskyddsstyrelsen ‚Äì AI och GDPR |

### Forskning och f√∂rdjupning
| Resurs | Beskrivning |
|--------|-------------|
| **[Lunds universitet ‚Äì AI-forskning](https://www.ai.lu.se/)** | Svensk akademisk forskning om AI |
| **[RISE](https://www.ri.se/sv/expertisomraden/ai)** | Forskningsinstitut med AI-fokus |
| **[Gender Shades](http://gendershades.org/)** | Banbrytande forskning om bias (Buolamwini) |
| **[Anthropic Research](https://www.anthropic.com/research)** | Hur Claude √§r designad f√∂r s√§kerhet |

---

## Kunskapstest

### Fr√•ga 1
Vad √§r en "hallucination" i AI-sammanhang?

- A) N√§r AI v√§grar svara
- B) N√§r AI genererar trov√§rdig men fabricerad information
- C) N√§r AI ger samma svar upprepade g√•nger
- D) N√§r AI missar relevant information

**R√§tt svar:** B

---

### Fr√•ga 2
Vilken typ av information ska du ALDRIG dela med √∂ppna AI-verktyg?

- A) Publikt tillg√§ngliga rapporter
- B) Generella branschfr√•gor
- C) Personuppgifter och aff√§rshemligheter
- D) Fr√•gor om projektmetodik

**R√§tt svar:** C

---

### Fr√•ga 3
Vilken svensk lag √§r s√§rskilt viktig att beakta vid AI-anv√§ndning i offentlig sektor?

- A) Marknadsf√∂ringslagen
- B) Offentlighets- och sekretesslagen (OSL)
- C) Produktansvarslagen
- D) Konsumenttj√§nstlagen

**R√§tt svar:** B

---

### Fr√•ga 4
Vad kr√§ver MBL (Medbest√§mmandelagen) vid AI-inf√∂rande?

- A) Att AI-leverant√∂ren godk√§nner anv√§ndningen
- B) Att facket informeras och f√∂rhandling sker innan beslut
- C) Att alla anst√§llda genomg√•r AI-utbildning
- D) Att IMY godk√§nner implementeringen

**R√§tt svar:** B

---

### Fr√•ga 5
Vad √§r ett tecken p√• att AI kan vara p√•verkad av bias?

- A) Svaret √§r grammatiskt korrekt
- B) Svaret bekr√§ftar dina antaganden utan kritik
- C) Svaret √§r l√•ngt och detaljerat
- D) Svaret inneh√•ller citat

**R√§tt svar:** B

---

## Sammanfattning

- **Kvalitetsrisker** inkluderar hallucinationer och kontextblindhet ‚Äì verifiera alltid
- **Bias finns** i alla AI-system ‚Äì ifr√•gas√§tt ensidiga svar
- **Informationss√§kerhet** kr√§ver anonymisering av k√§nslig information
- **EU AI Act** st√§ller krav p√• transparens och AI-literacy
- **Professionellt omd√∂me** inneb√§r att g√∂ra medvetna avv√§gningar, inte att f√∂lja checklistor

---

*G√• vidare till Modul 6: F√∂rankring och fortsatt l√§rande ‚Üí*
